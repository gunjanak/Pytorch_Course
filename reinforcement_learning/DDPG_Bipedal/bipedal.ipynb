{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "GAMMA = 0.99\n",
    "TAU = 0.005\n",
    "LR_ACTOR = 0.0001\n",
    "LR_CRITIC = 0.001\n",
    "BUFFER_SIZE = 1000000\n",
    "BATCH_SIZE = 64\n",
    "NOISE_DECAY = 0.99\n",
    "MAX_EPISODES = 1000\n",
    "MAX_TIMESTEPS = 2000\n",
    "SAVE_PATH = \"./ddpg_bipedalwalker\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janak/Documents/Pytorch_CPU/venv/lib/python3.10/site-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/janak/Documents/Pytorch_CPU/venv/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/janak/Documents/Pytorch_CPU/venv/lib/python3.10/site-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[32]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed for reproducibility\n",
    "SEED = 32\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "env = gym.make('BipedalWalker-v3')\n",
    "env.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor Network\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, max_action):\n",
    "        super(Actor, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 400)\n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        self.fc3 = nn.Linear(300, action_dim)\n",
    "        self.max_action = max_action\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        return x * self.max_action\n",
    "\n",
    "# Critic Network\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim + action_dim, 400)\n",
    "        self.fc2 = nn.Linear(400, 300)\n",
    "        self.fc3 = nn.Linear(300, 1)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state, action], 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Replay Buffer\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        return np.array(states), np.array(actions), np.array(rewards), np.array(next_states), np.array(dones)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "# DDPG Agent\n",
    "class DDPGAgent:\n",
    "    def __init__(self, state_dim, action_dim, max_action):\n",
    "        self.actor = Actor(state_dim, action_dim, max_action).to(device)\n",
    "        self.actor_target = Actor(state_dim, action_dim, max_action).to(device)\n",
    "        self.actor_target.load_state_dict(self.actor.state_dict())\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=LR_ACTOR)\n",
    "\n",
    "        self.critic = Critic(state_dim, action_dim).to(device)\n",
    "        self.critic_target = Critic(state_dim, action_dim).to(device)\n",
    "        self.critic_target.load_state_dict(self.critic.state_dict())\n",
    "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=LR_CRITIC)\n",
    "\n",
    "        self.replay_buffer = ReplayBuffer(BUFFER_SIZE)\n",
    "        self.max_action = max_action\n",
    "        self.noise = 0.1\n",
    "\n",
    "    def select_action(self, state):\n",
    "        state = torch.FloatTensor(state.reshape(1, -1)).to(device)\n",
    "        return self.actor(state).cpu().data.numpy().flatten()\n",
    "\n",
    "    def train(self):\n",
    "        if self.replay_buffer.size() < BATCH_SIZE:\n",
    "            return\n",
    "\n",
    "        states, actions, rewards, next_states, dones = self.replay_buffer.sample(BATCH_SIZE)\n",
    "\n",
    "        states = torch.FloatTensor(states).to(device)\n",
    "        actions = torch.FloatTensor(actions).to(device)\n",
    "        rewards = torch.FloatTensor(rewards).unsqueeze(1).to(device)\n",
    "        next_states = torch.FloatTensor(next_states).to(device)\n",
    "        dones = torch.FloatTensor(dones).unsqueeze(1).to(device)\n",
    "\n",
    "        # Critic loss\n",
    "        target_actions = self.actor_target(next_states)\n",
    "        target_q = self.critic_target(next_states, target_actions)\n",
    "        target_q = rewards + ((1 - dones) * GAMMA * target_q).detach()\n",
    "\n",
    "        current_q = self.critic(states, actions)\n",
    "        critic_loss = nn.MSELoss()(current_q, target_q)\n",
    "\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # Actor loss\n",
    "        actor_loss = -self.critic(states, self.actor(states)).mean()\n",
    "\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # Update target networks\n",
    "        for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "            target_param.data.copy_(TAU * param.data + (1 - TAU) * target_param.data)\n",
    "\n",
    "        for param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
    "            target_param.data.copy_(TAU * param.data + (1 - TAU) * target_param.data)\n",
    "\n",
    "    def add_to_replay_buffer(self, state, action, reward, next_state, done):\n",
    "        self.replay_buffer.add(state, action, reward, next_state, done)\n",
    "\n",
    "    def save(self, filename):\n",
    "        torch.save(self.actor.state_dict(), filename + \"_actor.pth\")\n",
    "        torch.save(self.critic.state_dict(), filename + \"_critic.pth\")\n",
    "\n",
    "    def load(self, filename):\n",
    "        self.actor.load_state_dict(torch.load(filename + \"_actor.pth\"))\n",
    "        self.critic.load_state_dict(torch.load(filename + \"_critic.pth\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize environment and agent\n",
    "# env = gym.make('BipedalWalker-v3')\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "max_action = float(env.action_space.high[0])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "agent = DDPGAgent(state_dim, action_dim, max_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janak/Documents/Pytorch_CPU/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Reward: -104.74681636101627\n",
      "Episode: 1, Reward: -112.61592918835186\n",
      "Episode: 2, Reward: -122.21226414155713\n",
      "Episode: 3, Reward: -132.23586421377738\n",
      "Episode: 4, Reward: -125.58899066855001\n",
      "Episode: 5, Reward: -102.04380804349775\n",
      "Episode: 6, Reward: -129.0697555354034\n",
      "Episode: 7, Reward: -108.3844748090671\n",
      "Episode: 8, Reward: -124.2452241349934\n",
      "Episode: 9, Reward: -114.6601941691709\n",
      "Episode: 10, Reward: -109.14364149126148\n",
      "Episode: 11, Reward: -107.44776705151115\n",
      "Episode: 12, Reward: -124.66014167003361\n",
      "Episode: 13, Reward: -140.50777176418677\n",
      "Episode: 14, Reward: -129.91921054979665\n",
      "Episode: 15, Reward: -82.39351351050772\n",
      "Episode: 16, Reward: -124.75079445758698\n",
      "Episode: 17, Reward: -113.88315727439512\n",
      "Episode: 18, Reward: -125.98248427167685\n",
      "Episode: 19, Reward: -117.57510091269506\n",
      "Episode: 20, Reward: -112.38861185132747\n",
      "Episode: 21, Reward: -128.14594840927776\n",
      "Episode: 22, Reward: -123.30861826861235\n",
      "Episode: 23, Reward: -116.56068815341568\n",
      "Episode: 24, Reward: -128.5525548489558\n",
      "Episode: 25, Reward: -107.59196867544904\n",
      "Episode: 26, Reward: -99.57494239196973\n",
      "Episode: 27, Reward: -110.11138564972738\n",
      "Episode: 28, Reward: -112.96172153376173\n",
      "Episode: 29, Reward: -106.8611358756159\n",
      "Episode: 30, Reward: -80.05521516306393\n",
      "Episode: 31, Reward: -165.6477696661807\n",
      "Episode: 32, Reward: -111.17046079716955\n",
      "Episode: 33, Reward: -114.0876545560927\n",
      "Episode: 34, Reward: -114.76682778297233\n",
      "Episode: 35, Reward: -111.74757578308167\n",
      "Episode: 36, Reward: -119.88298839333787\n",
      "Episode: 37, Reward: -111.9265068683469\n",
      "Episode: 38, Reward: -118.06894133596012\n",
      "Episode: 39, Reward: -105.50969447699273\n",
      "Episode: 40, Reward: -106.54050191293491\n",
      "Episode: 41, Reward: -141.10355678284083\n",
      "Episode: 42, Reward: -118.67164460455706\n",
      "Episode: 43, Reward: -124.36199489974929\n",
      "Episode: 44, Reward: -102.06231808945628\n",
      "Episode: 45, Reward: -98.94726567248696\n",
      "Episode: 46, Reward: -114.4635583344625\n",
      "Episode: 47, Reward: -100.99949774206954\n",
      "Episode: 48, Reward: -94.29064509755746\n",
      "Episode: 49, Reward: -102.63236491084909\n",
      "Episode: 50, Reward: -121.81953900808797\n",
      "Episode: 51, Reward: -98.20858169654697\n",
      "Episode: 52, Reward: -96.57836126270409\n",
      "Episode: 53, Reward: -100.71629537671083\n",
      "Episode: 54, Reward: -100.22741124091401\n",
      "Episode: 55, Reward: -102.68145884901718\n",
      "Episode: 56, Reward: -99.58492953478545\n",
      "Episode: 57, Reward: -161.82844800954246\n",
      "Episode: 58, Reward: -104.11759982609225\n",
      "Episode: 59, Reward: -108.56882233883356\n",
      "Episode: 60, Reward: -141.00303862518595\n",
      "Episode: 61, Reward: -96.20103233407028\n",
      "Episode: 62, Reward: -116.7449551085806\n",
      "Episode: 63, Reward: -119.59926323278667\n",
      "Episode: 64, Reward: -105.5957622183362\n",
      "Episode: 65, Reward: -99.55217126682608\n",
      "Episode: 66, Reward: -118.43041728181662\n",
      "Episode: 67, Reward: -91.9437919299233\n",
      "Episode: 68, Reward: -92.54647188332807\n",
      "Episode: 69, Reward: -93.3936649427634\n",
      "Episode: 70, Reward: -102.69059172811392\n",
      "Episode: 71, Reward: -103.47537677208484\n",
      "Episode: 72, Reward: -98.52274501450341\n",
      "Episode: 73, Reward: -88.08668043355738\n",
      "Episode: 74, Reward: -127.95175158132054\n",
      "Episode: 75, Reward: -93.22264061194863\n",
      "Episode: 76, Reward: -98.87567607655889\n",
      "Episode: 77, Reward: -97.56648831721651\n",
      "Episode: 78, Reward: -110.60254640580001\n",
      "Episode: 79, Reward: -107.47798211333738\n",
      "Episode: 80, Reward: -99.11505358887975\n",
      "Episode: 81, Reward: -101.69743976423621\n",
      "Episode: 82, Reward: -133.36242116626573\n",
      "Episode: 83, Reward: -134.98380384739633\n",
      "Episode: 84, Reward: -132.8420819230464\n",
      "Episode: 85, Reward: -81.68421676109189\n",
      "Episode: 86, Reward: -73.85351816058524\n",
      "Episode: 87, Reward: -121.47644335758056\n",
      "Episode: 88, Reward: -102.8649972562294\n",
      "Episode: 89, Reward: -91.74435593577232\n",
      "Episode: 90, Reward: -91.95569965633405\n",
      "Episode: 91, Reward: -96.2066343823631\n",
      "Episode: 92, Reward: -154.93279135929734\n",
      "Episode: 93, Reward: -121.91729463022635\n",
      "Episode: 94, Reward: -148.07137193596589\n",
      "Episode: 95, Reward: -103.14313058607799\n",
      "Episode: 96, Reward: -99.99508461976313\n",
      "Episode: 97, Reward: -169.73269472142835\n",
      "Episode: 98, Reward: -114.68910254312475\n",
      "Episode: 99, Reward: -112.82198037959387\n",
      "Episode: 100, Reward: -122.12258835230443\n",
      "Episode: 101, Reward: -131.8538615963048\n",
      "Episode: 102, Reward: -121.96119582127014\n",
      "Episode: 103, Reward: -114.57345416652227\n",
      "Episode: 104, Reward: -119.04946524201875\n",
      "Episode: 105, Reward: -110.15227341553668\n",
      "Episode: 106, Reward: -114.17069612125843\n",
      "Episode: 107, Reward: -112.90191667151875\n",
      "Episode: 108, Reward: -118.23042620198044\n",
      "Episode: 109, Reward: -113.88234343218467\n",
      "Episode: 110, Reward: -109.24576969885699\n",
      "Episode: 111, Reward: -113.27731904898562\n",
      "Episode: 112, Reward: -114.83143154267441\n",
      "Episode: 113, Reward: -114.44405110752827\n",
      "Episode: 114, Reward: -123.29397702181706\n",
      "Episode: 115, Reward: -114.97260335263708\n",
      "Episode: 116, Reward: -116.43777849705057\n",
      "Episode: 117, Reward: -121.597401894842\n",
      "Episode: 118, Reward: -110.31270568868943\n",
      "Episode: 119, Reward: -112.4991266791556\n",
      "Episode: 120, Reward: -100.82017499186972\n",
      "Episode: 121, Reward: -122.06712275411027\n",
      "Episode: 122, Reward: -108.15822460771149\n",
      "Episode: 123, Reward: -108.59027308668897\n",
      "Episode: 124, Reward: -107.55324589081144\n",
      "Episode: 125, Reward: -118.91638589806703\n",
      "Episode: 126, Reward: -33.053656084924505\n",
      "Episode: 127, Reward: -119.69566671098292\n",
      "Episode: 128, Reward: -120.4151447965282\n",
      "Episode: 129, Reward: -119.60339544862218\n",
      "Episode: 130, Reward: -120.30469745292018\n",
      "Episode: 131, Reward: -125.41957109583434\n",
      "Episode: 132, Reward: -121.94944652565206\n",
      "Episode: 133, Reward: -121.64913012598993\n",
      "Episode: 134, Reward: -114.4991948129911\n",
      "Episode: 135, Reward: -114.5557680449965\n",
      "Episode: 136, Reward: -118.41211642689719\n",
      "Episode: 137, Reward: -116.39122622456857\n",
      "Episode: 138, Reward: -117.16663652602233\n",
      "Episode: 139, Reward: -132.0998922625159\n",
      "Episode: 140, Reward: -148.5079481884352\n",
      "Episode: 141, Reward: -163.4187900937829\n",
      "Episode: 142, Reward: -132.33805304678168\n",
      "Episode: 143, Reward: -105.98564880984209\n",
      "Episode: 144, Reward: -110.051955796542\n",
      "Episode: 145, Reward: -188.52374108634183\n",
      "Episode: 146, Reward: -127.63398244882039\n",
      "Episode: 147, Reward: -110.58062971265025\n",
      "Episode: 148, Reward: -134.90485777952134\n",
      "Episode: 149, Reward: -186.59030561630016\n",
      "Episode: 150, Reward: -116.88075750724398\n",
      "Episode: 151, Reward: -224.55856690528904\n",
      "Episode: 152, Reward: -126.96743051169655\n",
      "Episode: 153, Reward: -103.77904302370196\n",
      "Episode: 154, Reward: -164.4396040471727\n",
      "Episode: 155, Reward: -129.069762983498\n",
      "Episode: 156, Reward: -147.43043994519786\n",
      "Episode: 157, Reward: -188.73277794629809\n",
      "Episode: 158, Reward: -122.99575279588157\n",
      "Episode: 159, Reward: -118.08542034313392\n",
      "Episode: 160, Reward: -129.1012173549226\n",
      "Episode: 161, Reward: -132.63331897689318\n",
      "Episode: 162, Reward: -124.56122805198282\n",
      "Episode: 163, Reward: -132.73375498657677\n",
      "Episode: 164, Reward: -126.03203692315378\n",
      "Episode: 165, Reward: -159.6805481862084\n",
      "Episode: 166, Reward: -101.34434757371156\n",
      "Episode: 167, Reward: -129.32460176499555\n",
      "Episode: 168, Reward: -108.65436643206574\n",
      "Episode: 169, Reward: -112.00585418374408\n",
      "Episode: 170, Reward: -116.630070042145\n",
      "Episode: 171, Reward: -118.33733816557091\n",
      "Episode: 172, Reward: -115.72083568250925\n",
      "Episode: 173, Reward: -116.64652276468932\n",
      "Episode: 174, Reward: -121.78207736817475\n",
      "Episode: 175, Reward: -121.31696311178852\n",
      "Episode: 176, Reward: -116.95343979266148\n",
      "Episode: 177, Reward: -114.56601279705113\n",
      "Episode: 178, Reward: -115.62343232099784\n",
      "Episode: 179, Reward: -142.7197205328432\n",
      "Episode: 180, Reward: -107.81613819718125\n",
      "Episode: 181, Reward: -145.2114233006838\n",
      "Episode: 182, Reward: -182.43884095255407\n",
      "Episode: 183, Reward: -130.32978437933716\n",
      "Episode: 184, Reward: -157.57895939409389\n",
      "Episode: 185, Reward: -134.65467444442746\n",
      "Episode: 186, Reward: -159.47310536002266\n",
      "Episode: 187, Reward: -159.35004992096717\n",
      "Episode: 188, Reward: -114.97814099839796\n",
      "Episode: 189, Reward: -112.90194429410846\n",
      "Episode: 190, Reward: -132.58062274079754\n",
      "Episode: 191, Reward: -140.32019025923458\n",
      "Episode: 192, Reward: -139.6553867487957\n",
      "Episode: 193, Reward: -130.1602477412495\n",
      "Episode: 194, Reward: -96.46132927152942\n",
      "Episode: 195, Reward: -104.67893811023495\n",
      "Episode: 196, Reward: -133.5680915155387\n",
      "Episode: 197, Reward: -145.22890705450916\n",
      "Episode: 198, Reward: -101.1065712314031\n",
      "Episode: 199, Reward: -98.6317609574338\n",
      "Episode: 200, Reward: -114.18635427858922\n",
      "Episode: 201, Reward: -80.46565211937559\n",
      "Episode: 202, Reward: -135.08112996668808\n",
      "Episode: 203, Reward: -154.357607642128\n",
      "Episode: 204, Reward: -147.87035512910032\n",
      "Episode: 205, Reward: -116.12231722738052\n",
      "Episode: 206, Reward: -52.410833169568704\n",
      "Episode: 207, Reward: -119.48788025708852\n",
      "Episode: 208, Reward: -155.62171386962973\n",
      "Episode: 209, Reward: -142.5859972794596\n",
      "Episode: 210, Reward: -181.39969369550943\n",
      "Episode: 211, Reward: -139.50856238956203\n",
      "Episode: 212, Reward: -112.26368208097821\n",
      "Episode: 213, Reward: -119.92491421006719\n",
      "Episode: 214, Reward: -143.72608430215413\n",
      "Episode: 215, Reward: -160.6262593031595\n",
      "Episode: 216, Reward: -142.80551165942447\n",
      "Episode: 217, Reward: -125.42518949178829\n",
      "Episode: 218, Reward: -141.38075170173124\n",
      "Episode: 219, Reward: -125.4302860159089\n",
      "Episode: 220, Reward: -128.76102717348508\n",
      "Episode: 221, Reward: -129.83041418913587\n",
      "Episode: 222, Reward: -118.87061251975342\n",
      "Episode: 223, Reward: -147.50150886453315\n",
      "Episode: 224, Reward: -142.5781859026392\n",
      "Episode: 225, Reward: -141.56017919327766\n",
      "Episode: 226, Reward: -124.00592792535629\n",
      "Episode: 227, Reward: -123.79439153557374\n",
      "Episode: 228, Reward: -124.77795464268024\n",
      "Episode: 229, Reward: -133.31404981733922\n",
      "Episode: 230, Reward: -119.97734417184515\n",
      "Episode: 231, Reward: -139.0670054812355\n",
      "Episode: 232, Reward: -98.4407207044141\n",
      "Episode: 233, Reward: -227.2171712572743\n",
      "Episode: 234, Reward: -162.54805885669217\n",
      "Episode: 235, Reward: -111.98109924933495\n",
      "Episode: 236, Reward: -103.43893266785867\n",
      "Episode: 237, Reward: -107.3131263744433\n",
      "Episode: 238, Reward: -98.32934776678667\n",
      "Episode: 239, Reward: -148.03149844493552\n",
      "Episode: 240, Reward: -129.15403100037932\n",
      "Episode: 241, Reward: -87.24683838035591\n",
      "Episode: 242, Reward: -104.49069905614472\n",
      "Episode: 243, Reward: -93.74596448981843\n",
      "Episode: 244, Reward: -77.15188601518292\n",
      "Episode: 245, Reward: -103.22682910318919\n",
      "Episode: 246, Reward: -97.05326455209615\n",
      "Episode: 247, Reward: -79.96336437197796\n",
      "Episode: 248, Reward: -109.35860509917046\n",
      "Episode: 249, Reward: -102.52722933328441\n",
      "Episode: 250, Reward: -161.23053109071643\n",
      "Episode: 251, Reward: -127.06924689439852\n",
      "Episode: 252, Reward: -125.29731029775591\n",
      "Episode: 253, Reward: -123.82334222152487\n",
      "Episode: 254, Reward: -140.63990963378512\n",
      "Episode: 255, Reward: -114.87613223859985\n",
      "Episode: 256, Reward: -129.05672128707656\n",
      "Episode: 257, Reward: -81.80005114048276\n",
      "Episode: 258, Reward: -85.87053032390534\n",
      "Episode: 259, Reward: -170.00988284480536\n",
      "Episode: 260, Reward: -95.25404637648747\n",
      "Episode: 261, Reward: -96.40933140316272\n",
      "Episode: 262, Reward: -89.70286884690525\n",
      "Episode: 263, Reward: -130.8562305078435\n",
      "Episode: 264, Reward: -137.29014745121563\n",
      "Episode: 265, Reward: -102.00059956567864\n",
      "Episode: 266, Reward: -135.07829230400168\n",
      "Episode: 267, Reward: -85.32865110544738\n",
      "Episode: 268, Reward: -103.3799321234033\n",
      "Episode: 269, Reward: -186.46244575173637\n",
      "Episode: 270, Reward: -194.15406665536455\n",
      "Episode: 271, Reward: -177.5950130265312\n",
      "Episode: 272, Reward: -94.19990715965886\n",
      "Episode: 273, Reward: -130.7364274710245\n",
      "Episode: 274, Reward: -130.20399776051195\n",
      "Episode: 275, Reward: -95.43468210023916\n",
      "Episode: 276, Reward: -121.89355120370031\n",
      "Episode: 277, Reward: -104.93573935242318\n",
      "Episode: 278, Reward: -62.3003934661727\n",
      "Episode: 279, Reward: -162.99876570886113\n",
      "Episode: 280, Reward: -165.6204654420323\n",
      "Episode: 281, Reward: -170.3381400922379\n",
      "Episode: 282, Reward: -107.20521010500744\n",
      "Episode: 283, Reward: -117.68273512706365\n",
      "Episode: 284, Reward: -124.98997093180719\n",
      "Episode: 285, Reward: -129.12581090467643\n",
      "Episode: 286, Reward: -134.2824460747494\n",
      "Episode: 287, Reward: -131.7985159986315\n",
      "Episode: 288, Reward: -117.38981148288687\n",
      "Episode: 289, Reward: -141.4124877284849\n",
      "Episode: 290, Reward: -107.33013617513883\n",
      "Episode: 291, Reward: -112.091347020986\n",
      "Episode: 292, Reward: -124.93426081218553\n",
      "Episode: 293, Reward: -107.94958472173477\n",
      "Episode: 294, Reward: -129.01375396770771\n",
      "Episode: 295, Reward: -122.99497201367772\n",
      "Episode: 296, Reward: -123.51286167313253\n",
      "Episode: 297, Reward: -155.52154404015107\n",
      "Episode: 298, Reward: -112.26386993131794\n",
      "Episode: 299, Reward: -107.24560983355542\n",
      "Episode: 300, Reward: -138.17556744721588\n",
      "Episode: 301, Reward: -111.77734735991228\n",
      "Episode: 302, Reward: -111.21039119077689\n",
      "Episode: 303, Reward: -118.8263390777339\n",
      "Episode: 304, Reward: -107.82539786530937\n",
      "Episode: 305, Reward: -103.18766695514282\n",
      "Episode: 306, Reward: -103.05895834814908\n",
      "Episode: 307, Reward: -90.74110499274393\n",
      "Episode: 308, Reward: -125.76080359495697\n",
      "Episode: 309, Reward: -109.80489655098319\n",
      "Episode: 310, Reward: -116.98924429722801\n",
      "Episode: 311, Reward: -101.3272672156346\n",
      "Episode: 312, Reward: -102.03693268425036\n",
      "Episode: 313, Reward: -102.54495260655365\n",
      "Episode: 314, Reward: -107.32295812678036\n",
      "Episode: 315, Reward: -100.98296272861529\n",
      "Episode: 316, Reward: -65.35748479752553\n",
      "Episode: 317, Reward: -100.92749685075292\n",
      "Episode: 318, Reward: -96.26066709528436\n",
      "Episode: 319, Reward: -87.01656376089116\n",
      "Episode: 320, Reward: -110.22537409418035\n",
      "Episode: 321, Reward: -91.4655474385497\n",
      "Episode: 322, Reward: -98.98209190503243\n",
      "Episode: 323, Reward: -91.00596275738665\n",
      "Episode: 324, Reward: -66.69843321870684\n",
      "Episode: 325, Reward: -85.44550577760789\n",
      "Episode: 326, Reward: -96.66771159366124\n",
      "Episode: 327, Reward: -91.02743972170973\n",
      "Episode: 328, Reward: -58.199908065210494\n",
      "Episode: 329, Reward: -111.0507270605077\n",
      "Episode: 330, Reward: -89.03809720366776\n",
      "Episode: 331, Reward: 1.20185608988605\n",
      "Episode: 332, Reward: -112.56314929191905\n",
      "Episode: 333, Reward: -50.62107607203873\n",
      "Episode: 334, Reward: -24.969842618644766\n",
      "Episode: 335, Reward: -114.46820397410173\n",
      "Episode: 336, Reward: -87.21655848902913\n",
      "Episode: 337, Reward: -104.10826851137426\n",
      "Episode: 338, Reward: -85.78910180612264\n",
      "Episode: 339, Reward: -60.879896134239516\n",
      "Episode: 340, Reward: -127.1128509951345\n",
      "Episode: 341, Reward: -37.869505553152614\n",
      "Episode: 342, Reward: -23.359276681947684\n",
      "Episode: 343, Reward: -116.43988085634403\n",
      "Episode: 344, Reward: -90.05090267159346\n",
      "Episode: 345, Reward: -116.42470437884296\n",
      "Episode: 346, Reward: -126.71930583742879\n",
      "Episode: 347, Reward: -106.80376503268764\n",
      "Episode: 348, Reward: -52.816174149749806\n",
      "Episode: 349, Reward: -88.85761918038608\n",
      "Episode: 350, Reward: -114.60431049718146\n",
      "Episode: 351, Reward: -105.25763809981811\n",
      "Episode: 352, Reward: -102.05580766654552\n",
      "Episode: 353, Reward: -109.38118053821741\n",
      "Episode: 354, Reward: -103.76447362816675\n",
      "Episode: 355, Reward: -98.51662507519325\n",
      "Episode: 356, Reward: -38.22176907472273\n",
      "Episode: 357, Reward: -89.2896177793632\n",
      "Episode: 358, Reward: -83.54354765408235\n",
      "Episode: 359, Reward: -42.70030380321213\n",
      "Episode: 360, Reward: -126.34799478213401\n",
      "Episode: 361, Reward: -140.91940923717868\n",
      "Episode: 362, Reward: -98.37860006816472\n",
      "Episode: 363, Reward: -68.23972765033618\n",
      "Episode: 364, Reward: -119.66834172892443\n",
      "Episode: 365, Reward: -122.5222449380612\n",
      "Episode: 366, Reward: -108.14226056244826\n",
      "Episode: 367, Reward: -115.71306900890563\n",
      "Episode: 368, Reward: -116.21271936445625\n",
      "Episode: 369, Reward: -111.92661362789477\n",
      "Episode: 370, Reward: -136.8121880789106\n",
      "Episode: 371, Reward: -104.85278585029066\n",
      "Episode: 372, Reward: -130.68087999652428\n",
      "Episode: 373, Reward: -120.7325622819931\n",
      "Episode: 374, Reward: -120.8340365641143\n",
      "Episode: 375, Reward: -96.73704653007742\n",
      "Episode: 376, Reward: -89.42838031288554\n",
      "Episode: 377, Reward: -81.61811623547521\n",
      "Episode: 378, Reward: -115.63602620189808\n",
      "Episode: 379, Reward: -86.2059159077462\n",
      "Episode: 380, Reward: -126.5195445805179\n",
      "Episode: 381, Reward: -101.39697575637584\n",
      "Episode: 382, Reward: -115.33442239569418\n",
      "Episode: 383, Reward: -108.77497994354732\n",
      "Episode: 384, Reward: -139.68307445634645\n",
      "Episode: 385, Reward: -132.87929290432962\n",
      "Episode: 386, Reward: -106.22115736213581\n",
      "Episode: 387, Reward: -121.23667910998637\n",
      "Episode: 388, Reward: -103.09432603875162\n",
      "Episode: 389, Reward: -112.74087068022621\n",
      "Episode: 390, Reward: -113.7094203222398\n",
      "Episode: 391, Reward: -91.32861318543296\n",
      "Episode: 392, Reward: -104.45344332142356\n",
      "Episode: 393, Reward: -100.18379659496313\n",
      "Episode: 394, Reward: -105.71390690877028\n",
      "Episode: 395, Reward: -91.80062663870403\n",
      "Episode: 396, Reward: -81.89241899729231\n",
      "Episode: 397, Reward: -35.38832715104748\n",
      "Episode: 398, Reward: -24.602512783417378\n",
      "Episode: 399, Reward: -50.668514037839735\n",
      "Episode: 400, Reward: -2.5382267842614934\n",
      "Episode: 401, Reward: 38.778160598099774\n",
      "Episode: 402, Reward: -162.00317734441626\n",
      "Episode: 403, Reward: -116.9009002424306\n",
      "Episode: 404, Reward: -108.37171635519755\n",
      "Episode: 405, Reward: -83.31279946374653\n",
      "Episode: 406, Reward: -142.5769503541496\n",
      "Episode: 407, Reward: -130.49601265122087\n",
      "Episode: 408, Reward: -95.63872625470069\n",
      "Episode: 409, Reward: -134.9388699325763\n",
      "Episode: 410, Reward: -72.9006008741504\n",
      "Episode: 411, Reward: -86.69453210402635\n",
      "Episode: 412, Reward: -54.02940463147855\n",
      "Episode: 413, Reward: -77.89544842985475\n",
      "Episode: 414, Reward: -78.45658948218497\n",
      "Episode: 415, Reward: -55.247647432505424\n",
      "Episode: 416, Reward: -86.65217501343915\n",
      "Episode: 417, Reward: -79.86392586926138\n",
      "Episode: 418, Reward: -95.04701409753865\n",
      "Episode: 419, Reward: -82.87166930009599\n",
      "Episode: 420, Reward: -21.044042501906375\n",
      "Episode: 421, Reward: -41.96253511665029\n",
      "Episode: 422, Reward: -106.78210119148157\n",
      "Episode: 423, Reward: -101.66742859873058\n",
      "Episode: 424, Reward: -106.73616640825047\n",
      "Episode: 425, Reward: -113.87826062109559\n",
      "Episode: 426, Reward: -114.01290406954978\n",
      "Episode: 427, Reward: -107.09417093675631\n",
      "Episode: 428, Reward: -104.00640036597173\n",
      "Episode: 429, Reward: -103.62797792096835\n",
      "Episode: 430, Reward: -84.97085476593686\n",
      "Episode: 431, Reward: -97.42895235248314\n",
      "Episode: 432, Reward: -67.37365916968649\n",
      "Episode: 433, Reward: -54.444421370884406\n",
      "Episode: 434, Reward: -106.22501524674018\n",
      "Episode: 435, Reward: -116.09538480483306\n",
      "Episode: 436, Reward: -107.42240634439852\n",
      "Episode: 437, Reward: -105.71523651186769\n",
      "Episode: 438, Reward: -110.8682354332383\n",
      "Episode: 439, Reward: -107.01954332122637\n",
      "Episode: 440, Reward: -97.82264563889227\n",
      "Episode: 441, Reward: -101.56867747108011\n",
      "Episode: 442, Reward: -73.94335398323733\n",
      "Episode: 443, Reward: -125.2806513467174\n",
      "Episode: 444, Reward: -78.3547830627107\n",
      "Episode: 445, Reward: -69.15304245625602\n",
      "Episode: 446, Reward: -89.75059690739286\n",
      "Episode: 447, Reward: -24.44910128761844\n",
      "Episode: 448, Reward: -143.54134321995448\n",
      "Episode: 449, Reward: -48.019926918377976\n",
      "Episode: 450, Reward: -24.91111117012906\n",
      "Episode: 451, Reward: -103.30361824629723\n",
      "Episode: 452, Reward: -124.42469658627581\n",
      "Episode: 453, Reward: -134.73210106464438\n",
      "Episode: 454, Reward: -64.54916283222803\n",
      "Episode: 455, Reward: -137.00854691079303\n",
      "Episode: 456, Reward: -26.063560712366325\n",
      "Episode: 457, Reward: -70.33092894725095\n",
      "Episode: 458, Reward: -91.58285247531802\n",
      "Episode: 459, Reward: -53.263366159954835\n",
      "Episode: 460, Reward: -93.33386644011799\n",
      "Episode: 461, Reward: -98.40825338677794\n",
      "Episode: 462, Reward: -76.1737905434646\n",
      "Episode: 463, Reward: -79.65697092098586\n",
      "Episode: 464, Reward: -47.217037814397834\n",
      "Episode: 465, Reward: -55.32432332767637\n",
      "Episode: 466, Reward: -86.28658138919347\n",
      "Episode: 467, Reward: -94.7661936346995\n",
      "Episode: 468, Reward: -52.56017667328519\n",
      "Episode: 469, Reward: -89.73146527339833\n",
      "Episode: 470, Reward: -91.27127822188012\n",
      "Episode: 471, Reward: -108.71821510500804\n",
      "Episode: 472, Reward: -63.29052583696113\n",
      "Episode: 473, Reward: -110.88052982840415\n",
      "Episode: 474, Reward: -96.30641703154726\n",
      "Episode: 475, Reward: -114.62368037817382\n",
      "Episode: 476, Reward: -117.13966863251295\n",
      "Episode: 477, Reward: -59.79061884177998\n",
      "Episode: 478, Reward: -30.86535541799084\n",
      "Episode: 479, Reward: -70.9699386201569\n",
      "Episode: 480, Reward: -43.508449998588766\n",
      "Episode: 481, Reward: -97.27474988452558\n",
      "Episode: 482, Reward: -99.69161681001233\n",
      "Episode: 483, Reward: -96.29135172216075\n",
      "Episode: 484, Reward: -96.3111507880236\n",
      "Episode: 485, Reward: -89.25149886427003\n",
      "Episode: 486, Reward: -95.8911311964827\n",
      "Episode: 487, Reward: -97.71155642589142\n",
      "Episode: 488, Reward: -92.00394046154695\n",
      "Episode: 489, Reward: -92.78669955660274\n",
      "Episode: 490, Reward: -123.26337120356195\n",
      "Episode: 491, Reward: -105.98191237722908\n",
      "Episode: 492, Reward: -103.87484508527368\n",
      "Episode: 493, Reward: -100.00237004862747\n",
      "Episode: 494, Reward: -99.34132125345495\n",
      "Episode: 495, Reward: -99.40835526059591\n",
      "Episode: 496, Reward: -97.0651413418977\n",
      "Episode: 497, Reward: -97.58944552681035\n",
      "Episode: 498, Reward: -96.9727516179262\n",
      "Episode: 499, Reward: -95.3462924698463\n",
      "Episode: 500, Reward: -82.70025699766843\n",
      "Episode: 501, Reward: -92.26188123712485\n",
      "Episode: 502, Reward: -55.50842499128654\n",
      "Episode: 503, Reward: -80.86664160615359\n",
      "Episode: 504, Reward: -95.09875447028364\n",
      "Episode: 505, Reward: -86.23846535422305\n",
      "Episode: 506, Reward: -31.992886033437088\n",
      "Episode: 507, Reward: -20.04621920139637\n",
      "Episode: 508, Reward: -84.71252595717992\n",
      "Episode: 509, Reward: 102.99787403009101\n",
      "Episode: 510, Reward: -105.02109235662073\n",
      "Episode: 511, Reward: -87.13421385910506\n",
      "Episode: 512, Reward: -12.395441117234597\n",
      "Episode: 513, Reward: -38.29798255638313\n",
      "Episode: 514, Reward: -70.76754077517022\n",
      "Episode: 515, Reward: 90.79620539053678\n",
      "Episode: 516, Reward: -100.29157945528559\n",
      "Episode: 517, Reward: -67.3387295332053\n",
      "Episode: 518, Reward: -48.68164274110301\n",
      "Episode: 519, Reward: -102.59838663268452\n",
      "Episode: 520, Reward: 37.49322053480137\n",
      "Episode: 521, Reward: -28.148640136221445\n",
      "Episode: 522, Reward: -48.36186078634026\n",
      "Episode: 523, Reward: -53.63420339364218\n",
      "Episode: 524, Reward: -74.68597627920003\n",
      "Episode: 525, Reward: 10.891776380745881\n",
      "Episode: 526, Reward: -45.40183514531923\n",
      "Episode: 527, Reward: -62.79031238171483\n",
      "Episode: 528, Reward: -71.12477241803813\n",
      "Episode: 529, Reward: 137.61465291839934\n",
      "Episode: 530, Reward: -15.013641133823953\n",
      "Episode: 531, Reward: 53.74574304013558\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Training loop\n",
    "for episode in range(MAX_EPISODES):\n",
    "    state = env.reset()\n",
    "    episode_reward = 0\n",
    "    agent.noise *= NOISE_DECAY\n",
    "\n",
    "    for t in range(MAX_TIMESTEPS):\n",
    "        action = agent.select_action(state) + np.random.normal(0, agent.noise, size=action_dim)\n",
    "        action = action.clip(env.action_space.low, env.action_space.high)\n",
    "        \n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.add_to_replay_buffer(state, action, reward, next_state, done)\n",
    "\n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "\n",
    "        agent.train()\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    print(f\"Episode: {episode}, Reward: {episode_reward}\")\n",
    "    episode_rewards.append(episode_reward)\n",
    "\n",
    "    # Save the model every 10 episodes\n",
    "    if (episode + 1) % 10 == 0:\n",
    "        agent.save(SAVE_PATH)\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
